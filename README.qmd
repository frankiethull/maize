---
title: "{maize} package"
format: gfm
knitr:
  opts_chunk:
    fig.path: "man/figures/README-"
---

# maize <img src="man/figures/logo.png" align="right" height="139" alt="" />
    
{maize} `r emo::ji("corn")` is an extension library for kernels & support vector machines in tidymodels! The package consists of additional kernel bindings that are not available in the {parsnip} or {recipes} package. Many of the kernels are ported from {kernlab}, additional kernels have been added directly to maize transposed from [Python](https://github.com/gmum/pykernels/blob/master/pykernels/regular.py) and [Julia](https://juliagaussianprocesses.github.io/KernelFunctions.jl/stable/kernels/) packages. 


{parnsip} has three kernels available: linear, radial basis function, & polynomial. {maize} extends to further kernels, other engines, and adds steps for {recipes}: 

```{r}
#| echo: false

# parsnip bindings --
# kernlab
kernlab_models <- data.frame(
  extension   = "{parsnip}",
  maize   = c("svm_laplace", "svm_tanh", "svm_bessel", "svm_anova_rbf", 
              "svm_spline","svm_cossim", "svm_cauchy", "svm_tanimoto",
              "svm_sorenson", "svm_tstudent", "svm_fourier", "svm_wavelet",
              "svm_string",
              "lssvm_laplace",
              "rvm_laplace", "kqr_laplace"),
  engine  = c(rep("kernlab::ksvm", 13), 
              "kernlab::lssvm",
              "kernlab::rvm",  "kernlab::kqr"),
  mode    = c(rep("regression & classification", 12), 
              "classification",
              "classification",
              rep("regression", 2))
) 

# ebmc 
ebmc_models <- data.frame(
  extension   = "{parsnip}",
  maize   = c("bag_svm_laplace", "rus_boost_svm_laplace", "ada_boost_svm_laplace"),
  engine  = c("ebmc::ub", "ebmc::rus",  "ebmc::adam2"),
  mode    = c(rep("binary-classification", 3))
) 

# mildsvm 
mild_models <- data.frame(
  extension  = "{parsnip}",
  maize  = c("misvm_orova_rbf"),
  engine = c("mildsvm::misvm_orova"),
  mode   = c("classification")
)

# modeltime bindings --
modeltime_models <- data.frame(
  extension = "{modeltime}",
  maize     = c("arima_svm_laplace"),
  engine    = c("forecast::Arima + maize::svm_laplace"),
  mode      = c("regression")
)

# recipes bindings --
maize_recipes <- data.frame(
  extension = "{recipes}",
  maize  = c("step_kpca_laplace", "step_kpca_tanh", 
             "step_kha_laplace", "step_kha_tanh",
             "step_kfa_laplace",
             "step_kfm_nystrom"),
  engine = c(rep("kernlab::kpca", 2),
             rep("kernlab::kha",  2),
             rep("kernlab::kfa",  1),
             "mildsvm::kfm_nystrom"),
  mode   = "transformation steps"
)

# probably bindings --
maize_probably <- data.frame(
  extension = "{probably}",
  maize   = c("int_conformal_quantile_svm", "cal_estimate_svm"),
  engine  = c("qrsvm::qrsvm", "kernlab::ksvm"),
  mode    = c("prediction intervals", "calibrator")
)

# applicable bindings --
maize_applicable <- data.frame(
  extension = "{applicable}",
  maize     = "apd_svm_novel_detection",
  engine    = "kernlab::ksvm",
  mode      = "one-SVC novelty detection"
)

# corrr inspired --
maize_corrr <- data.frame(
  extension = "{corrr}",
  maize     = "kcca_correlate",
  engine    = "kernlab::kcca",
  mode      = "kernel canonical correlation analysis"
)

```

## Installation

You can install the development version of maize from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("frankiethull/maize")
```

## engines

#### {kernlab} 

SVMs with Specialty Kernels. Contains additional regression and classification techniques such as LS-SVMs.
```{r}
#| echo: false
kernlab_models |> 
  gt::gt() |> 
  gt::tab_header(title = paste0("{kernlab} bindings", emo::ji("corn"))) |>
  gt::as_raw_html()
```

#### {mildsvm}

Multi-Instance Learners with SVMs. In particular, MIL with ordinal outcomes using One-vs-All.
```{r}
#| echo: false
mild_models |>
  gt::gt() |> 
  gt::tab_header(title = paste0("{mildsvm} bindings", emo::ji("corn"))) |>
  gt::as_raw_html()
```

#### {ebmc}

Bagging and Boosting weak learners via Random Under Sampling for binary classification.
```{r}
#| echo: false
ebmc_models |>
  gt::gt() |> 
  gt::tab_header(title = paste0("{ebmc} bindings", emo::ji("corn"))) |>
  gt::as_raw_html()
```

### recipes

Steps for feature engineering data via kernel related methods. 
```{r}
#| echo: false
maize_recipes |>
  gt::gt() |> 
  gt::tab_header(title = paste0("pre-processors", emo::ji("corn"))) |>
  gt::as_raw_html()
```

### probably

Point calibration and conformal quantile regression with SVMs (QRSVM) for prediction intervals. 
```{r}
#| echo: false
maize_probably |>
  gt::gt() |> 
  gt::tab_header(title = paste0("post-processors", emo::ji("corn"))) |>
  gt::as_raw_html()
```

### modeltime

A special implementation of SVMs for time series regression. ARIMA & AutoARIMA with SVM Errors are registered in maize. The *harvestime* vignette showcases how-to-use ARIMA-SVMs & Recursive SVMs.
```{r}
#| echo: false
modeltime_models |>
  gt::gt() |> 
  gt::tab_header(title = paste0("{modeltime} bindings", emo::ji("corn"))) |>
  gt::as_raw_html()
```


### applicable

One-Class SVMs for novelty detection
```{r}
#| echo: false
maize_applicable |>
  gt::gt() |> 
  gt::tab_header(title = paste0("applicability", emo::ji("corn"))) |>
  gt::as_raw_html()

```


### corrr

Inspired by corrr, returns a tidy data frame class (kcor_df) for Kernel Canonical Correlation Analysis:
```{r}
#| echo: false
maize_corrr |>
  gt::gt() |> 
  gt::tab_header(title = paste0("KCCA", emo::ji("corn"))) |>
  gt::as_raw_html()

```

